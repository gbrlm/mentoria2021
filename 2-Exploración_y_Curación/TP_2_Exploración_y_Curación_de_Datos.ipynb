{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_2_Exploración_y_Curación_de_Datos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq1iwBo-YnFC"
      },
      "source": [
        "# Mentoría\n",
        "## Análisis de datos sobre la violencia contra la mujer.\n",
        "##Introducción\n",
        "\n",
        "En la siguiente notebook, se presentará la consigna a seguir para el segundo práctico de la materia Análisis y Curación de datos. El objetivo consiste en identificar e implementar los pasos necesarios para la limpieza del dataset de trabajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D2c9eX8Fgrx"
      },
      "source": [
        "# Consigna para Curación y Exploración del Dataset\n",
        "\n",
        "## I. Rutina de curación y objetivo\n",
        "\n",
        "Inicialmente, con el objetivo de preparar los datos que alimentarán futuros modelos de aprendizaje automático (ML), se propone seguir la siguiente [checklist](https://dimewiki.worldbank.org/wiki/Checklist:_Data_Cleaning) para la limpieza de los datos de nuestro proyecto. Esto es una guía sobre que decisiones tomar, algunas de ellas no correspondrán aplicar o no serán necesarias.\n",
        "\n",
        "Cada decisión tomada deberá quedar registrada de manera explícita y clara. Luego de pasar por todos los puntos de la checklist propuesta, deberán almacenar en un nuevo archivo los datos resultantes.\n",
        "\n",
        "Principalmente deberían tener en cuenta los siguientes ítems:\n",
        "\n",
        "* Considerar la posibilidad de renombrar las variables (columnas) de manera más descriptiva.\n",
        "\n",
        "* Datos repetidos. ¿Existen?, ¿cómo detectarlos?\n",
        "\n",
        "* Datos faltantes y datos nulos. ¿Existen?, ¿tienen algún significado?, ¿podemos completarlos?\n",
        "\n",
        "* Consistencia de los datos. ¿Existe contradicción en los datos?, ¿qué hacemos si la hay?\n",
        "\n",
        "* Outliers. ¿Existen?, ¿cómo los tratamos?\n",
        "\n",
        "* Indagar en la forma en que está presentada la información. ¿Es posible reordenar la información?, ¿es posible comprimir el dataset para guardarlo de manera más eficiente?\n",
        "\n",
        "* Considerar la posibilidad de crear nuevas variables (columnas) en base a las ya disponibles (o quizás incorporando otra información). Esto puede ser útil para algún análisis que nos propongamos hacer a futuro.\n",
        "\n",
        "\n",
        "Recuerden que la ciencia de datos es un proceso circular, continuo y no lineal. Es decir, si los datos requieren de mayor procesamiento para satisfacer las necesidades de algoritmos de ML (cualesquiera de ellos), vamos a volver a la etapa inicial para, por ejemplo, crear nuevas features, tomar decisiones diferentes sobre valores faltantes o valores atípicos, descartar features, entre otras.\n",
        "\n",
        "## II. Análisis en profundidad del contenido\n",
        "\n",
        "Una vez analizada la Checklist, lo que vamos a hacer es profundizar aún más el análisis y tomar decisiones que se consideren pertinentes. Por supuesto, tomadas las decisiones sobre el análisis y curación estas deberán quedar registradas.\n",
        "\n",
        "Al finalizar con el práctico, las siguientes preguntas deberán quedar respondidas.\n",
        "\n",
        "* ¿Existen filas repetidas?, ¿en caso de haber, que significaría en este dataset en particular?\n",
        "\n",
        "* ¿Existen datos que deban ser anonimizados?, ¿qué se debería hacer con estos datos en caso de existir? Dado que el dataset es una encuesta, ¿qué datos personales presenta y cómo están incluidos en el dataset?\n",
        "\n",
        "* ¿Qué tipos de variables se presentan?, ¿es necesario recodearlas en otros tipos?\n",
        "\n",
        "* ¿Existen valores faltante?, ¿qué tratamiento se les puede dar?, ¿qué herramientas posee Python y Pandas en particular para tratarlo?\n",
        "\n",
        "* ¿Existen valores faltante?, ¿qué tratamiento se les puede dar y qué decisiones toman en estos casos?\n",
        "\n",
        "* ¿Es posible comprimir los datos originales?, ¿qué técnicas creen que se pueden emplear?\n",
        "\n",
        "Esta lista intenta abarcar todas las posibles irregularidades en los datos, pero puede no ser exhaustiva. Cualquier análisis adicional de consistencia que deseen agregar porque lo consideran pertinente, será bienvenido y valorado.\n",
        "\n",
        "\n",
        "## Entregables\n",
        "\n",
        "El entregable de este práctico consiste en un Notebook de dos partes. Primero un informe donde presenten los ítems de la checklist realizados y el análisis de contenido completo, explicando las decisiones tomadas en cada etapa junto al/los datasets generados en el proceso de análisis y curación. Luego el script que deberá mostrar el proceso realizado sobre el dataset. \n",
        "\n",
        "Opcional: Generar y entregar un script (.py) que contenga una función para la curación de los datos de acuerdo a sus decisiones y que genere un nuevo dataset para un subconjunto de variables dadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rEXjmPjFghD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}